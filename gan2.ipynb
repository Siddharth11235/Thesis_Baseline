{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import itertools\n",
    "import functools\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.nn.utils import weight_norm\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "from librosa.filters import constant_q as librosa_cqt_fn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from torch.nn import functional as F\n",
    "import functools\n",
    "import utils\n",
    "from dataset import AudioTransformSet\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "OUT_CHANNELS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./logdir/experiment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cycleRandGAN(object):\n",
    "\tdef __init__(self, args):\n",
    "\t\t##The Network\n",
    "\t\tself.g_AB =  Generator(conv_dim=args.ngf, n_res_blocks=2).cuda() #initialise generator with n mel channels\n",
    "\t\t\n",
    "\t\tself.g_BA =  Generator(conv_dim=args.ngf, n_res_blocks=2).cuda() #initialise generator with n mel channels\n",
    "\t\tself.Da = Discriminator(conv_dim=args.ndf).cuda() #initialize discriminator\n",
    "\t\tself.Db =  Discriminator(conv_dim=args.ndf).cuda() #initialize discriminator\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#The Losses\n",
    "\t\tself.MSE = nn.MSELoss()\n",
    "\t\tself.L1 = nn.L1Loss()\n",
    "\n",
    "\t\t# Optimizers\n",
    "\t\t#####################################################\n",
    "\t\tself.g_optimizer = torch.optim.Adam(itertools.chain(self.g_AB.parameters(),self.g_BA.parameters()), lr=args.lr, betas=(0.5, 0.999))\n",
    "\t\tself.d_optimizer = torch.optim.Adam(itertools.chain(self.Da.parameters(),self.Db.parameters()), lr=args.lr, betas=(0.5, 0.999))\n",
    "\t\t\n",
    "\n",
    "\t\tself.g_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.g_optimizer, lr_lambda=utils.LambdaLR(args.epochs, 0, args.decay_epoch).step)\n",
    "\t\tself.d_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.d_optimizer, lr_lambda=utils.LambdaLR(args.epochs, 0, args.decay_epoch).step)\n",
    "\n",
    "\t\t\n",
    "\t\t#Load potential checkpoint\n",
    "\t\tif not os.path.isdir(args.checkpoint_dir):\n",
    "\t\t\tos.makedirs(args.checkpoint_dir)\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tckpt = utils.load_checkpoint('%slatest_rcnn.ckpt' % (args.checkpoint_dir))\n",
    "\t\t\tself.start_epoch = ckpt['epoch']\n",
    "\t\t\tself.Da.load_state_dict(ckpt['Da'])\n",
    "\t\t\tself.Db.load_state_dict(ckpt['Db'])\n",
    "\t\t\tself.g_AB.load_state_dict(ckpt['Gab'])\n",
    "\t\t\tself.g_BA.load_state_dict(ckpt['Gba'])\n",
    "\t\t\tself.d_optimizer.load_state_dict(ckpt['d_optimizer'])\n",
    "\t\t\tself.g_optimizer.load_state_dict(ckpt['g_optimizer'])\n",
    "\t\texcept:\n",
    "\t\t\tprint(' [*] No checkpoint!')\n",
    "\t\t\tself.start_epoch = 0\n",
    "\tdef train(self,args):\n",
    "\t\ttrain_set=AudioTransformSet(args.dataset_dir+\"Joni_Mitchell/files.txt\", args.dataset_dir+\"Nancy_Sinatra/files.txt\", args.seq_len, \n",
    "\t\tsampling_rate=22050, augment=True)\n",
    "\t\tdataloader = DataLoader(train_set, batch_size=args.batch_size, num_workers=4)   \n",
    "\t\t\n",
    "\t\t\n",
    "\t\ta_fake_sample = utils.Sample_from_Pool()\n",
    "\t\tb_fake_sample = utils.Sample_from_Pool()\n",
    "\t\n",
    "\t\tfor epoch in range(self.start_epoch, args.epochs):\n",
    "\n",
    "\t\t\tlr = self.g_optimizer.param_groups[0]['lr']\n",
    "\t\t\tprint('learning rate = %.7f' % lr)\n",
    "\n",
    "\t\t\tfor i, data in enumerate(dataloader):\n",
    "\t\t\t\t# step\n",
    "\n",
    "\t\t\t\tstep = epoch *len(dataloader) + i + 1\n",
    "\t\t\t\tprint(step)\n",
    "\t\t\t\n",
    "\t\t\t\ta_real = data[0]\n",
    "\t\t\t\tb_real = data[1]\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t\ta_r_spec = torchaudio.transforms.Spectrogram()(a_real)\n",
    "\t\t\t\tb_r_spec = torchaudio.transforms.Spectrogram()(b_real)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t\tprint(\"Shape of a-spectrogram: {}\".format(a_r_spec.size()))\n",
    "\t\t\t\tprint(\"Shape of b-spectrogram: {}\".format(b_r_spec.size()))\n",
    "\t\t\t\t# Generator Computations\n",
    "\t\t\t\t##################################################\n",
    "\n",
    "\t\t\t\tset_grad([self.Da, self.Db], False)\n",
    "\t\t\t\tself.g_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\t\t\t\t# Forward pass through generators\n",
    "\t\t\t\t##################################################\n",
    "\t\t\t\ta_fake = self.g_AB(b_r_spec.cuda())\n",
    "\t\t\t\tb_fake = self.g_BA(a_r_spec.cuda())\n",
    "\n",
    "\n",
    "\t\t\t\tprint(\"Shape of a-fake spectrogram: {}\".format(a_fake.size()))\n",
    "\t\t\t\tprint(\"Shape of b-fake spectrogram: {}\".format(b_fake.size()))\n",
    "\n",
    "\t\t\t\t\n",
    "\n",
    "\n",
    "\t\t\t\ta_recon = self.g_AB(b_fake)\n",
    "\t\t\t\tb_recon = self.g_BA(a_fake)\n",
    "\n",
    "\n",
    "\t\t\t\ta_idt = self.g_AB(a_r_spec.cuda())\n",
    "\t\t\t\tb_idt = self.g_BA(b_r_spec.cuda())\n",
    "\n",
    "\t\t\t\ta_idt = self.fft(a_idt).detach()\n",
    "\t\t\t\tb_idt = self.fft(b_idt).detach()\n",
    "\n",
    "\t\t\t\tprint(\"Shape of a_recon spectrogram: {}\".format(a_recon.size()))\n",
    "\t\t\t\tprint(\"Shape of b_recon spectrogram: {}\".format(b_recon.size()))\n",
    "\n",
    "\t\t\t\t# Identity losses\n",
    "\t\t\t\t###################################################\n",
    "\t\t\t\ta_idt_loss = self.L1(a_idt, a_r_spec) * args.lamda * args.idt_coef\n",
    "\t\t\t\tb_idt_loss = self.L1(b_idt, b_r_spec) * args.lamda * args.idt_coef\n",
    "\n",
    "\t\t\t\t# Adversarial losses\n",
    "\t\t\t\t###################################################\n",
    "\t\t\t\ta_fake_dis = self.Da(a_fake)\n",
    "\t\t\t\tb_fake_dis = self.Db(b_fake)\n",
    "\n",
    "\t\t\t\tprint(a_fake_dis.size())\n",
    "\t\t\t\treal_label = utils.cuda(Variable(torch.ones(a_fake_dis.size())))\n",
    "\n",
    "\n",
    "\t\t\t\ta_gen_loss = self.MSE(a_fake_dis, real_label)\n",
    "\t\t\t\tb_gen_loss = self.MSE(b_fake_dis, real_label)\n",
    "\n",
    "\t\t\t\t# Cycle consistency losses\n",
    "\t\t\t\t###################################################\n",
    "\t\t\t\ta_cycle_loss = self.L1(a_recon, a_r_spec) * args.lamda\n",
    "\t\t\t\tb_cycle_loss = self.L1(b_recon, b_r_spec) * args.lamda\n",
    "\n",
    "\t\t\t\t# Total generators losses\n",
    "\t\t\t\t###################################################\n",
    "\t\t\t\tgen_loss = a_gen_loss + b_gen_loss + a_cycle_loss + b_cycle_loss + a_idt_loss + b_idt_loss\n",
    "\n",
    "\t\t\t\t# Update generators\n",
    "\t\t\t\t###################################################\n",
    "\t\t\t\tgen_loss.backward(retain_graph=True)\n",
    "\t\t\t\tself.g_optimizer.step()\n",
    "\n",
    "\n",
    "\t\t\t\t# Discriminator Computations\n",
    "\t\t\t\t#################################################\n",
    "\n",
    "\n",
    "\t\t\t\tset_grad([self.Da, self.Db], True)\n",
    "\t\t\t\tself.d_optimizer.zero_grad()\n",
    "\n",
    "\t\t\t\t# Sample from history of generated images\n",
    "\t\t\t\t#################################################\n",
    "\t\t\t\ta_f_spec = Variable(torch.Tensor(a_fake_sample([a_f_spec.cpu().data.numpy()])))\n",
    "\t\t\t\tb_f_spec = Variable(torch.Tensor(b_fake_sample([b_f_spec.cpu().data.numpy()])))\n",
    "\t\t\t\ta_f_spec, b_f_spec = utils.cuda([a_f_spec, b_f_spec])\n",
    "\n",
    "\n",
    "\t\t\t\tprint(\"Shape of a-fake spectrogram: {}\".format(a_f_spec.size()))\n",
    "\t\t\t\tprint(\"Shape of b-fake spectrogram: {}\".format(b_f_spec.size()))\n",
    "\n",
    "\t\t\t\tprint(\"Shape of a-spectrogram: {}\".format(a_r_spec.size()))\n",
    "\t\t\t\tprint(\"Shape of b-spectrogram: {}\".format(b_r_spec.size()))\n",
    "\n",
    "\n",
    "\t\t\t\t# Forward pass through discriminators\n",
    "\t\t\t\t################################################# \n",
    "\t\t\t\ta_real_dis = self.Da(a_real)\n",
    "\t\t\t\ta_fake_dis = self.Da(a_fake)\n",
    "\t\t\t\tb_real_dis = self.Db(b_real)\n",
    "\t\t\t\tb_fake_dis = self.Db(b_fake)\n",
    "\t\t\t\treal_label = utils.cuda(Variable(torch.ones(a_real_dis.size())))\n",
    "\t\t\t\tfake_label = utils.cuda(Variable(torch.zeros(a_fake_dis.size())))\n",
    "\n",
    "\t\t\t\t# Discriminator losses\n",
    "\t\t\t\t##################################################\n",
    "\t\t\t\ta_dis_real_loss = self.MSE(a_real_dis, real_label)\n",
    "\t\t\t\ta_dis_fake_loss = self.MSE(a_fake_dis, fake_label)\n",
    "\t\t\t\tb_dis_real_loss = self.MSE(b_real_dis, real_label)\n",
    "\t\t\t\tb_dis_fake_loss = self.MSE(b_fake_dis, fake_label)\n",
    "\n",
    "\t\t\t\t# Total discriminators losses\n",
    "\t\t\t\ta_dis_loss = (a_dis_real_loss + a_dis_fake_loss)*0.5\n",
    "\t\t\t\tb_dis_loss = (b_dis_real_loss + b_dis_fake_loss)*0.5\n",
    "\n",
    "\t\t\t\t# Update discriminators\n",
    "\t\t\t\t##################################################\n",
    "\t\t\t\ta_dis_loss.backward(retain_graph=True)\n",
    "\t\t\t\tb_dis_loss.backward(retain_graph=True)\n",
    "\t\t\t\tself.d_optimizer.step()\n",
    "\n",
    "\t\t\t\t\t# every 1000 mini-batches...\n",
    "\n",
    "\t\t\t\t# ...log the running loss\n",
    "\t\t\t\twriter.add_scalar('DisA loss',  a_dis_loss / 1000,\n",
    "\t\t\t\t\t\tepoch * len(dataloader) + i)\n",
    "\t\t\t\twriter.add_scalar('DisB loss',  b_dis_loss / 1000,\n",
    "\t\t\t\t\t\tepoch * len(dataloader) + i)\n",
    "\t\t\t\t\n",
    "\t\t\t\twriter.add_scalar('Generator loss',  gen_loss / 1000,\n",
    "\t\t\t\t\t\tepoch * len(dataloader) + i)\n",
    "\n",
    "\n",
    "\t\t\t\tprint(\"Epoch: (%3d) (%5d/%5d) | Gen Loss:%.2e | Dis Loss:%.2e\" %(epoch, i + 1, len(dataloader), gen_loss,a_dis_loss+b_dis_loss))\n",
    "\n",
    "\t\t\t# Override the latest checkpoint\n",
    "\t\t\t#######################################################\n",
    "\t\t\tutils.save_checkpoint({'epoch': epoch + 1,\n",
    "\t\t\t\t\t\t\t\t   'Da': self.Da.state_dict(),\n",
    "\t\t\t\t\t\t\t\t   'Db': self.Db.state_dict(),\n",
    "\t\t\t\t\t\t\t\t   'Gab': self.g_AB.state_dict(),\n",
    "\t\t\t\t\t\t\t\t   'Gba': self.g_BA.state_dict(),\n",
    "\t\t\t\t\t\t\t\t   'd_optimizer': self.d_optimizer.state_dict(),\n",
    "\t\t\t\t\t\t\t\t   'g_optimizer': self.g_optimizer.state_dict()},\n",
    "\t\t\t\t\t\t\t\t  '%s/slatest_rcnn.ckpt' % (args.checkpoint_dir))\n",
    "\n",
    "\t\t\t# Update learning rates\n",
    "\t\t\t########################\n",
    "\t\t\tself.g_lr_scheduler.step()\n",
    "\t\t\tself.d_lr_scheduler.step()\n",
    "\n",
    "\tdef test(self,args):\n",
    "\t\ttest_set=AudioTransformSet(args.test_dir+\"Joni_Mitchell/files.txt\", args.test_dir+\"Nancy_Sinatra/files.txt\", args.seq_len, \n",
    "\t\tsampling_rate=22050, augment=True)\n",
    "\t\tdataloader = DataLoader(test_set, batch_size=1, num_workers=4) \n",
    "\t\tself.g_BA.eval()\n",
    "\t\tfor i, data in enumerate(dataloader):\n",
    "\t\t\tx = data[1]\n",
    "\t\t\tx = x.cuda()\n",
    "\t\t\tx_spec = self.fft(x).detach()\n",
    "\t\t\ty = self.g_BA(x_spec)\n",
    "\t\t\tprint (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_channels=32,out_channels= 32, kernel_size=(3, 1), stride=2, padding=1, batch_norm=True):\n",
    "\t\"\"\"Creates a convolutional layer, with optional batch normalization.\n",
    "\t\"\"\"\n",
    "\tlayers = []\n",
    "\tconv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "\t\t\t\t\t\t   kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "\t\n",
    "\tlayers.append(conv_layer)\n",
    "\n",
    "\tif batch_norm:\n",
    "\t\tlayers.append(nn.BatchNorm2d(out_channels))\n",
    "\treturn nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(in_channels, out_channels, kernel_size, stride=2, padding=1, batch_norm=True):\n",
    "\t\"\"\"Creates a transpose convolutional layer, with optional batch normalization.\n",
    "\t\"\"\"\n",
    "\tlayers = []\n",
    "\t# append transpose conv layer\n",
    "\tlayers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False))\n",
    "\t# optional batch norm layer\n",
    "\tif batch_norm:\n",
    "\t\tlayers.append(nn.BatchNorm2d(out_channels))\n",
    "\treturn nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\t\"\"\"Defines a residual block.\n",
    "\t   This adds an input x to a convolutional layer (applied to x) with the same size input and output.\n",
    "\t   These blocks allow a model to learn an effective transformation from one domain to another.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, conv_dim):\n",
    "\t\tsuper(ResidualBlock, self).__init__()\n",
    "\t\t# conv_dim = number of inputs\n",
    "\t\t\n",
    "\t\t# define two convolutional layers + batch normalization that will act as our residual function, F(x)\n",
    "\t\t# layers should have the same shape input as output; I suggest a kernel_size of 3\n",
    "\t\t\n",
    "\t\tself.conv_layer1 = conv(in_channels=conv_dim, out_channels=conv_dim, \n",
    "\t\t\t\t\t\t\t\tkernel_size=3, stride=1, padding=1, batch_norm=True)\n",
    "\t\t\n",
    "\t\tself.conv_layer2 = conv(in_channels=conv_dim, out_channels=conv_dim, \n",
    "\t\t\t\t\t\t\t   kernel_size=3, stride=1, padding=1, batch_norm=True)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\t# apply a ReLu activation the outputs of the first layer\n",
    "\t\t# return a summed output, x + resnet_block(x)\n",
    "\t\tout_1 = F.relu(self.conv_layer1(x))\n",
    "\t\tout_2 = x + self.conv_layer2(out_1)\n",
    "\t\treturn out_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\tdef __init__(self, conv_dim=16, n_res_blocks=2):\n",
    "\t\tsuper(Generator, self).__init__()\n",
    "\n",
    "\t\t# 2-D CNN\n",
    "\t\tself.conv1 = nn.Conv2d(1, conv_dim, kernel_size=(3, 1)\t, stride=1, padding=0)\n",
    "\t\tself.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "\t\tself.conv2 = nn.Conv2d(conv_dim, conv_dim*2, kernel_size=(3, 1)\t, stride=1, padding=0)\n",
    "\n",
    "\t\t# Set the random parameters to be constant.\n",
    "\t\tweight = torch.randn(self.conv1.weight.data.shape)\n",
    "\t\tself.conv1.weight = torch.nn.Parameter(weight, requires_grad=False)\n",
    "\t\tbias = torch.zeros(self.conv1.bias.data.shape)\n",
    "\t\tself.conv1.bias = torch.nn.Parameter(bias, requires_grad=False)\n",
    "\n",
    "\t\tres_layers = []\n",
    "\t\tfor layer in range(n_res_blocks):\n",
    "\t\t\tres_layers.append(ResidualBlock(conv_dim*2))\n",
    "\t\t# use sequential to create these layers\n",
    "\t\tself.res_blocks = nn.Sequential(*res_layers)\n",
    "\n",
    "\t\t# 3. Define the decoder part of the generator\n",
    "\t\t# two transpose convolutional layers and a third that looks a lot like the initial conv layer\n",
    "\t\tself.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
    "\t\t# no batch norm on last layer\n",
    "\t\tself.deconv2 = deconv(conv_dim, 1, 4, batch_norm=False)\n",
    "\n",
    "\tdef forward(self, x_delta):\n",
    "\t\tout = self.LeakyReLU(self.conv1(x_delta))\n",
    "\t\tout = self.LeakyReLU(self.conv2(out))\n",
    "\t\tout = self.res_blocks(out)\n",
    "\t\tout = F.relu(self.deconv1(out))\n",
    "\t\tout = F.tanh(self.deconv2(out))\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, conv_dim=16):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "\n",
    "\t\t# Define all convolutional layers\n",
    "\t\t# Should accept an RGB image as input and output a single value\n",
    "\n",
    "\t\t# Convolutional layers, increasing in depth\n",
    "\t\t# first layer has *no* batchnorm\n",
    "\t\tself.conv1 = conv(1, conv_dim, 4, batch_norm=False) # x, y = 64, depth 64\n",
    "\t\tself.conv2 = conv(conv_dim, conv_dim*2, 4) # (32, 32, 64)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# Classification layer\n",
    "\t\tself.conv5 = conv(conv_dim*2, 1, 4, stride=1, batch_norm=False)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# relu applied to all conv layers but last\n",
    "\t\tout = F.relu(self.conv1(x))\n",
    "\t\tout = F.relu(self.conv2(out))\n",
    "\t\t# last, classification layer\n",
    "\t\tout = self.conv5(out)\n",
    "\t\tprint (out.size())\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_grad(nets, requires_grad=False):\n",
    "\tfor net in nets:\n",
    "\t\tfor param in net.parameters():\n",
    "\t\t\tparam.requires_grad = requires_grad\n",
    "\n",
    "def weights_init(m):\n",
    "\tclassname = m.__class__.__name__\n",
    "\tif classname.find(\"Conv\") != -1:\n",
    "\t\tm.weight.data.normal_(0.0, 0.02)\n",
    "\telif classname.find(\"BatchNorm2d\") != -1:\n",
    "\t\tm.weight.data.normal_(1.0, 0.02)\n",
    "\t\tm.bias.data.fill_(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
